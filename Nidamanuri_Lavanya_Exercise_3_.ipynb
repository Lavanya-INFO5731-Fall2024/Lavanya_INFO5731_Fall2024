{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lavanya-INFO5731-Fall2024/Lavanya_INFO5731_Fall2024/blob/main/Nidamanuri_Lavanya_Exercise_3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 3**\n",
        "\n",
        "The purpose of this exercise is to explore various aspects of text analysis, including feature extraction, feature selection, and text similarity ranking.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of Friday, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting **text classification or text mining task** and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features. **Your dataset must be text.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "->Spam detection is an intriguing text classification job in which the aim is to determine if an email is spam or not (ham).\n",
        "  This is a binary classification issue in which text patterns assist detect undesired or hazardous information.\n",
        "->Here are five forms of characteristics that might be relevant in developing a spam detection model:\n",
        "  *Bag of Words / Term Frequency-Inverse Document Frequency\n",
        "  *N-grams (Bigrams, Trigrams)\n",
        "  *Email Metadata Features\n",
        "  *Presence of URLs and Hyperlinks\n",
        "  *Special Characters, Punctuation, and Capitalization\n",
        "\n",
        "->Bag of Words / Term Frequency-Inverse Document Frequency:\n",
        "  -Spam emails frequently contain specific keywords such as \"free,\" \"win,\" \"urgent,\" \"money,\" \"buy now,\" and so on.\n",
        "  These terms are common in spam, but less so in legal (ham) emails.\n",
        "  -TF-IDF reduces the effect of common, less-informative terms while emphasizing spam-related phrases.\n",
        "->N-grams (Bigrams, Trigrams):\n",
        "  -Spam sometimes includes terms like \"limited time offer\" or \"act now\".\n",
        "   These multi-word formulations convey more meaning than single words and frequently expose spam trends.\n",
        "  -Spam communications typically have more formulaic patterns that can be caught using n-grams.\n",
        "->Email Metadata Features:\n",
        "  -Spam subject lines sometimes include eye-catching or spectacular statements (for example, \"Congratulations! You've Won!\").\n",
        "  -The sender's email address may contain patterns such as strange domains, odd strings, or unfamiliar contacts.\n",
        "  -The timestamp might be important since spam emails are typically sent at unusual hours or in mass.\n",
        "->Presence of URLs and Hyperlinks:\n",
        "  -Many spam emails attempt to steer visitors to phishing sites or fraudulent offers.\n",
        "   A large number of URLs or truncated URLs (e.g., bit.ly) may signal spam email.\n",
        "  -The presence of strange or unusual domain names in the links may indicate spam.\n",
        "->Special Characters, Punctuation, and Capitalization:\n",
        "  -Spam communications frequently include exclamation marks, dollar signs, or other eye-catching symbols to convey urgency or a call to action (e.g., \"BUY NOW!!!\").\n",
        "  -Excessive use of capitalized phrases such as \"FREE,\" \"WIN,\" or \"ACT NOW\" is typical in spam emails but uncommon in real correspondence.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed847938-79a0-46ac-c71f-1ee0dbb0774a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 98.36%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99       779\n",
            "        spam       0.99      0.96      0.97       381\n",
            "\n",
            "    accuracy                           0.98      1160\n",
            "   macro avg       0.99      0.98      0.98      1160\n",
            "weighted avg       0.98      0.98      0.98      1160\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "# Load the dataset (spam.csv or another dataset)\n",
        "df = pd.read_csv('spam_assaain.csv', encoding='latin-1')  # Adjust path as needed\n",
        "\n",
        "# Check the structure of the dataset\n",
        "df.head()\n",
        "\n",
        "# Assuming 'target' is the label (spam/ham) and 'text' is the email content\n",
        "df = df[['text', 'target']]  # Keep only the relevant columns\n",
        "\n",
        "# Convert labels to binary: spam = 1, ham = 0 (assuming 0 = ham, 1 = spam)\n",
        "df['target'] = df['target'].map({1: 1, 0: 0})  # 1 for spam, 0 for ham\n",
        "df.columns = ['email', 'label']  # Rename the columns for consistency\n",
        "\n",
        "# Now the DataFrame is ready with 'email' and 'label' columns.\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenize and lemmatize\n",
        "    tokens = text.split()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to the 'email' column\n",
        "df['email'] = df['email'].apply(preprocess_text)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['email'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize TF-IDF vectorizer (you can use CountVectorizer for Bag of Words if you prefer)\n",
        "tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))  # Extract unigrams and bigrams\n",
        "\n",
        "# Fit the vectorizer on the training data and transform both training and testing sets\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')  # Print accuracy in percentage\n",
        "\n",
        "# Print detailed classification report\n",
        "print(classification_report(y_test, y_pred, target_names=['ham', 'spam']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7806ecf4-597f-4d20-d761-40770ea16c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Feature  MI Score\n",
            "18           the  0.231049\n",
            "15       quality  0.231049\n",
            "14       product  0.231049\n",
            "19          this  0.143841\n",
            "7             is  0.143841\n",
            "0          again  0.132304\n",
            "1        amazing  0.132304\n",
            "22          with  0.132304\n",
            "21          will  0.132304\n",
            "20       totally  0.132304\n",
            "17     satisfied  0.132304\n",
            "13      positive  0.132304\n",
            "12   outstanding  0.132304\n",
            "11           not  0.132304\n",
            "10      negative  0.132304\n",
            "9           love  0.132304\n",
            "8             it  0.132304\n",
            "6     experience  0.132304\n",
            "5           ever  0.132304\n",
            "4   disappointed  0.132304\n",
            "3            buy  0.132304\n",
            "2            bad  0.132304\n",
            "23         worst  0.132304\n",
            "16        review  0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
            "  warnings.warn(msg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "# Required Libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# Sample Data (Text and Labels)\n",
        "texts = [\n",
        "    \"This is a positive review\",\n",
        "    \"I love this product, it's amazing\",\n",
        "    \"Worst experience ever, totally disappointed\",\n",
        "    \"This is a negative review\",\n",
        "    \"Not satisfied with the product, bad quality\",\n",
        "    \"The quality is outstanding, will buy again\",\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 0, 0, 1]  # 1 = Positive, 0 = Negative\n",
        "\n",
        "# Step 1: Convert text data into TF-IDF features\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Step 2: Calculate Mutual Information\n",
        "mi = mutual_info_classif(X, labels, discrete_features=True)\n",
        "\n",
        "# Step 3: Create a DataFrame to Display Feature Importance\n",
        "mi_scores = pd.DataFrame({'Feature': feature_names, 'MI Score': mi})\n",
        "\n",
        "# Sort the features by their MI score in descending order\n",
        "mi_scores = mi_scores.sort_values(by='MI Score', ascending=False)\n",
        "\n",
        "# Display the ranked features based on MI Score\n",
        "print(mi_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef55faf9-56ba-4a42-edd0-994bf4be0fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  email  similarity\n",
            "4937  gintare netzero net mon jun return path dmeizy...    0.830505\n",
            "3321  ia rogers com mon aug return path ia rogers co...    0.811449\n",
            "2954  fork admin xent com wed jul return path fork a...    0.740152\n",
            "3337  claudia_robinson eudoramail com mon aug return...    0.739608\n",
            "2418  fork admin xent com wed aug return path fork a...    0.736885\n",
            "4675  rssfeeds jmason org thu oct return path rssfee...    0.733521\n",
            "101   fork admin xent com mon dec return path fork a...    0.732922\n",
            "3296  exmh user admin redhat com fri sep return path...    0.732734\n",
            "5110  iiu owner taint org mon aug return path iiu ow...    0.730542\n",
            "5079  yipxyvihobzh ibm com tue aug return path yipxy...    0.728989\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Load a limited subset of the data (e.g., 100 samples)\n",
        "df_limited = df.sample(n=20, random_state=42)\n",
        "\n",
        "# Load the BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to encode text using BERT\n",
        "def encode_text_bert(text, max_len=512):\n",
        "    # Tokenize the input text and convert to input IDs, attention masks\n",
        "    inputs = tokenizer(text, return_tensors='pt', max_length=max_len, truncation=True, padding='max_length')\n",
        "    with torch.no_grad():  # Disable gradient calculations\n",
        "        outputs = model(**inputs)  # Pass the inputs to the BERT model\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :]  # Extract the CLS token representation\n",
        "    return embeddings\n",
        "\n",
        "# Preprocess the limited dataset using BERT embeddings\n",
        "df_limited['bert_embeddings'] = df_limited['email'].apply(lambda x: encode_text_bert(x).numpy().flatten())\n",
        "\n",
        "# Function to compute cosine similarity between query and documents\n",
        "def rank_documents_by_similarity(query, df_limited):\n",
        "    # Encode the query using BERT\n",
        "    query_embedding = encode_text_bert(query).numpy().flatten()\n",
        "\n",
        "    # Calculate cosine similarity between the query and each document\n",
        "    df_limited['similarity'] = df_limited['bert_embeddings'].apply(lambda x: cosine_similarity([query_embedding], [x])[0][0])\n",
        "\n",
        "    # Sort the dataframe by similarity in descending order\n",
        "    ranked_df = df_limited.sort_values(by='similarity', ascending=False)\n",
        "\n",
        "    return ranked_df[['email', 'similarity']]\n",
        "\n",
        "# Example query\n",
        "query = \"Limited time offer for free lottery entry\"\n",
        "\n",
        "# Rank documents by their similarity to the query\n",
        "ranked_df_limited = rank_documents_by_similarity(query, df_limited)\n",
        "\n",
        "# Display the top-ranked documents based on similarity\n",
        "print(ranked_df_limited.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on extracting features from text data. What were the key concepts or techniques you found most beneficial in understanding the process?\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Learing Experience\n",
        "-In order to work on extracting features from text data, I learnt how we can convert raw text into meaningful numerical representations\n",
        "that can be used as features in machine learning models. Below are few of the important concepts which I found of great use:\n",
        "*Text Vectorization : Bag of Words (BoW), Term Frequency-Inverse Document Frequency (TF-IDF), Word2Vec , BERT etc.\n",
        " Each has its own advantages. From simple frequency counts to capturing how words relate with each other.\n",
        "*Feature Selection: I had to learn and understand Chi-Square, Mutual Information, and Information Gain methods very well in\n",
        " order to select the right important features from the text data which would reduce the dimensions as well as improve model performance\n",
        " by keeping only the informative features.\n",
        "*Text Similarity: Learning to compute similarity between texts using BERT embeddings and cosine similarity helped me understand\n",
        " how deep learning models such as BERT internally represent text in a manner that captures context and semantics, which is critical\n",
        " for applications like document ranking and semantic search.\n",
        "\n",
        "Challenges\n",
        "-Text data generally have high dimensional feature spaces especially with traditional methods like Bag of Words or TF-IDF which is\n",
        "computationally expensive and introduces what is normally referred to as the curse of dimensionality.\n",
        "-Each of the feature selection method (e.g. Mutual Information, Chi-Square etc.) has certain pros and cons.\n",
        "Thus, which one is the best for a specific task is difficult to conclude without having some trials in that regard.\n",
        "BERT provides great contextual embeddings, but it is important to understand how these embeddings represent the meaning of text and\n",
        "how to fine-tune or use them for your similarity ranking NLP task.\n",
        "-BERT models are resource intensive, so if you try to use them on large datasets or for comparing similarities on multiple sentences,\n",
        "it will be very slow on low-end machines.\n",
        "\n",
        "Relevance to NLP\n",
        "-Feature Extraction is essential in NLP problems like text classification, sentiment analysis, topic modeling etc.\n",
        "Good feature representation and feature selection will help in building good models.\n",
        "-Text Similarity is very important in many natural language processing (NLP) applications. For instance, information retrieval\n",
        "(e.g., search engines), question answering, document clustering, etc. Among deep learning models, using BERT for semantic similarity\n",
        "is state-of-the-art in NLP.\n",
        "BERT and Contextual Embeddings are the new advancements which are happening in the NLP space. So learning how BERT can be used in\n",
        "real-time problems directly correlates to what is the modern NLP as of now and what is cutting edge.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}